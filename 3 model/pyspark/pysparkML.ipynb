{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.functions import col, when, length, size, split, udf, rand, size, regexp_replace\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
    "\n",
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, LogisticRegression, DecisionTreeClassifier, GBTClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/19 14:20:02 WARN Utils: Your hostname, Ordenador-portatil-de-Javier.local resolves to a loopback address: 127.0.0.1; using 192.168.0.28 instead (on interface en0)\n",
      "23/07/19 14:20:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/19 14:20:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import\n",
    "[Data Process](../../Data_Process/train_data_process.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|Lawsuit seeks inv...|\n",
      "|     0|There are very fe...|\n",
      "|     0|USA has gone to H...|\n",
      "|     0|AOC is a Puerto R...|\n",
      "|     0|Men: wOMen be OuT...|\n",
      "|     1|Then again, he do...|\n",
      "|     1|@gisewaaa we must...|\n",
      "|     1|cum gurgling fagg...|\n",
      "|     0|@dhiggins63 Satan...|\n",
      "|     1|Fuck you, you ret...|\n",
      "|     1|You next on the l...|\n",
      "|     1|Lmaooooo niggas a...|\n",
      "|     0|Everyday in Kashm...|\n",
      "|     1|Look at this fagg...|\n",
      "|     0|Britian needs to ...|\n",
      "|     0|Replace the word ...|\n",
      "|     1|These niggas Got ...|\n",
      "|     0|Wow you sound lik...|\n",
      "|     1|Fuck you've got a...|\n",
      "|     0|The State Departm...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hdfs_path = 'hdfs://ruta/archivo.csv'\n",
    "\n",
    "data = spark.read.json(\"../../../kaggle/data_json\")\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "161337"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to include all three dataframes in the training stage, the data is randomly mixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.orderBy(rand(seed=43))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is divided in train and test. Being the train the 80% of the total data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(data.count() * 0.8)\n",
    "\n",
    "df_train = data.limit(split_index)\n",
    "df_test = data.subtract(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data analysis has been completed in Jupyter, the text cleaning stage is started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweets require lots of cleaning but it is inefficient to clean every single tweet because that would consume too much time. A general approach must be implemented for cleaning.\n",
    "\n",
    "* The most common type of words that require cleaning in oov have punctuations at the start or end. Those words doesn't have embeddings because of the trailing punctuations. Punctuations #, @, !, ?, +, &, -, $, =, <, >, |, {, }, ^, ', (, ),[, ], *, %, ..., ', ., :, ; are separated from words\n",
    "* Special characters that are attached to words are removed completely\n",
    "* Contractions are expanded\n",
    "* Urls are removed\n",
    "* Character entity references are replaced with their actual symbols\n",
    "* Typos and slang are corrected, and informal abbreviations are written in their long forms\n",
    "* Some words are replaced with their acronyms and some words are grouped into one\n",
    "* Finally, hashtags and usernames contain lots of information about the context but they are written without spaces in between words so they don't have embeddings. Informational usernames and hashtags should be expanded but there are too many of them. Due to the project deadline, hashtags and usernames haven't been expanded in detail, a list of expanded usernames was taken in order to achive this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|I, a Catholic and...|\n",
      "|     1|ayo i even kill h...|\n",
      "|     0|Trans rights are ...|\n",
      "|     0|the eu siding wit...|\n",
      "|     0|   #   porn,   # ...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:===================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     0|Some women are ju...|\n",
      "|     0|Free Tay K   ?   ...|\n",
      "|     1|   *   Insert edg...|\n",
      "|     0|   @   lizforus L...|\n",
      "|     1|   &   amp   ;   ...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "replace_text = udf(lambda text: \n",
    "                    text.replace(\"å_\", \"\")\n",
    "                        .replace(\"fromåÊwounds\", \"from wounds\")\n",
    "                        .replace(\"åÊ\", \"\")\n",
    "                        .replace(\"åÈ\", \"\")\n",
    "                        .replace(\"JapÌ_n\", \"Japan\")\n",
    "                        .replace(\"Ì©\", \"e\")\n",
    "                        .replace(\"å¨\", \"\")\n",
    "                        .replace(\"SuruÌ¤\", \"Suruc\")\n",
    "                        .replace(\"åÇ\", \"\")\n",
    "                        .replace(\"å£3million\", \"3 million\")\n",
    "                        .replace(\"åÀ\", \"\")\n",
    "                        .replace(\"he's\", \"he is\")\n",
    "                        .replace(\"there's\", \"there is\")\n",
    "                        .replace(\"We're\", \"We are\")\n",
    "                        .replace(\"That's\", \"That is\")\n",
    "                        .replace(\"won't\", \"will not\")\n",
    "                        .replace(\"they're\", \"they are\")\n",
    "                        .replace(\"Can't\", \"Cannot\")\n",
    "                        .replace(\"wasn't\", \"was not\")\n",
    "                        .replace(\"aren't\", \"are not\")\n",
    "                        .replace(\"isn't\", \"is not\")\n",
    "                        .replace(\"What's\", \"What is\")\n",
    "                        .replace(\"haven't\", \"have not\")\n",
    "                        .replace(\"hasn't\", \"has not\")\n",
    "                        .replace(\"There's\", \"There is\")\n",
    "                        .replace(\"He's\", \"He is\")\n",
    "                        .replace(\"It's\", \"It is\")\n",
    "                        .replace(\"You're\", \"You are\")\n",
    "                        .replace(\"I'M\", \"I am\")\n",
    "                        .replace(\"shouldn't\", \"should not\")\n",
    "                        .replace(\"wouldn't\", \"would not\")\n",
    "                        .replace(\"i'm\", \"I am\")\n",
    "                        .replace(\"I'm\", \"I am\")\n",
    "                        .replace(\"Isn't\", \"is not\")\n",
    "                        .replace(\"Here's\", \"Here is\")\n",
    "                        .replace(\"you've\", \"you have\")\n",
    "                        .replace(\"we're\", \"we are\")\n",
    "                        .replace(\"what's\", \"what is\")\n",
    "                        .replace(\"couldn't\", \"could not\")\n",
    "                        .replace(\"we've\", \"we have\")\n",
    "                        .replace(\"who's\", \"who is\")\n",
    "                        .replace(\"y'all\", \"you all\")\n",
    "                        .replace(\"would've\", \"would have\")\n",
    "                        .replace(\"it'll\", \"it will\")\n",
    "                        .replace(\"we'll\", \"we will\")\n",
    "                        .replace(\"We've\", \"We have\")\n",
    "                        .replace(\"he'll\", \"he will\")\n",
    "                        .replace(\"Y'all\", \"You all\")\n",
    "                        .replace(\"Weren't\", \"Were not\")\n",
    "                        .replace(\"Didn't\", \"Did not\")\n",
    "                        .replace(\"they'll\", \"they will\")\n",
    "                        .replace(\"they'd\", \"they would\")\n",
    "                        .replace(\"DON'T\", \"DO NOT\")\n",
    "                        .replace(\"they've\", \"they have\")\n",
    "                        .replace(\"i'd\", \"I would\")\n",
    "                        .replace(\"should've\", \"should have\")\n",
    "                        .replace(\"where's\", \"where is\")\n",
    "                        .replace(\"we'd\", \"we would\")\n",
    "                        .replace(\"i'll\", \"I will\")\n",
    "                        .replace(\"weren't\", \"were not\")\n",
    "                        .replace(\"They're\", \"They are\")\n",
    "                        .replace(\"let's\", \"let us\")\n",
    "                        .replace(\"it's\", \"it is\")\n",
    "                        .replace(\"can't\", \"cannot\")\n",
    "                        .replace(\"don't\", \"do not\")\n",
    "                        .replace(\"you're\", \"you are\")\n",
    "                        .replace(\"i've\", \"I have\")\n",
    "                        .replace(\"that's\", \"that is\")\n",
    "                        .replace(\"i'll\", \"I will\")\n",
    "                        .replace(\"doesn't\", \"does not\")\n",
    "                        .replace(\"i'd\", \"I would\")\n",
    "                        .replace(\"didn't\", \"did not\")\n",
    "                        .replace(\"ain't\", \"am not\")\n",
    "                        .replace(\"you'll\", \"you will\")\n",
    "                        .replace(\"I've\", \"I have\")\n",
    "                        .replace(\"Don't\", \"do not\")\n",
    "                        .replace(\"I'll\", \"I will\")\n",
    "                        .replace(\"I'd\", \"I would\")\n",
    "                        .replace(\"Let's\", \"Let us\")\n",
    "                        .replace(\"you'd\", \"You would\")\n",
    "                        .replace(\"It's\", \"It is\")\n",
    "                        .replace(\"Ain't\", \"am not\")\n",
    "                        .replace(\"Haven't\", \"Have not\")\n",
    "                        .replace(\"Could've\", \"Could have\")\n",
    "                        .replace(\"youve\", \"you have\")\n",
    "                        .replace(\"donå«t\", \"do not\")\n",
    "                        .replace(\"@\", \" @ \")\n",
    "                        .replace(\"#\", \" # \")\n",
    "                        .replace(\"!\", \" ! \")\n",
    "                        .replace(\"?\", \" ? \")\n",
    "                        .replace(\"+\", \" + \")\n",
    "                        .replace(\"&\", \" & \")\n",
    "                        .replace(\"*\", \" * \")\n",
    "                        .replace(\"[\", \" [ \")\n",
    "                        .replace(\"]\", \" ] \")\n",
    "                        .replace(\"-\", \" - \")\n",
    "                        .replace(\"%\", \" % \")\n",
    "                        .replace(\".\", \" . \")\n",
    "                        .replace(\":\", \" : \")\n",
    "                        .replace(\"/\", \" / \")\n",
    "                        .replace(\"(\", \" ( \")\n",
    "                        .replace(\")\", \" ) \")\n",
    "                        .replace(\";\", \" ; \")\n",
    "                        .replace(\"$\", \" $ \")\n",
    "                        .replace(\"=\", \" = \")\n",
    "                        .replace(\">\", \" > \")\n",
    "                        .replace(\"<\", \" < \")\n",
    "                        .replace(\"|\", \" | \")\n",
    "                        .replace(\"{\", \" { \")\n",
    "                        .replace(\"}\", \" } \")\n",
    "                        .replace(\"^\", \" ^ \")\n",
    "                        .replace(\"'\", \" ' \")\n",
    "                        .replace(\"`\", \" ` \")\n",
    "                        .replace(\"...\", \" ... \")\n",
    "                        .replace(\"..\", \" ... \") if text is not None else None, StringType())\n",
    "\n",
    "\n",
    "\n",
    "df_train = df_train.withColumn(\"text\", replace_text(df_train[\"text\"]))\n",
    "df_test = df_test.withColumn(\"text\", replace_text(df_test[\"text\"]))\n",
    "\n",
    "# Mostrar el DataFrame transformado\n",
    "df_train.show(5)\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Tokenizer:** <br>\n",
    "The Tokenizer is a feature transformer that takes an input text column and splits it into individual words or tokens. It is used to preprocess the text data before applying any machine learning algorithms. In this case, the input text column is \"text_cleaned\" which contains the preprocessed and cleaned text data. The Tokenizer transforms the \"text_cleaned\" column into a new column called \"tokens\" where each row contains an array of tokens (words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|target|                text|               words|\n",
      "+------+--------------------+--------------------+\n",
      "|     0|I, a Catholic and...|[i, a, catholic, ...|\n",
      "|     1|ayo i even kill h...|[ayo, i, even, ki...|\n",
      "|     0|Trans rights are ...|[trans, rights, a...|\n",
      "|     0|the eu siding wit...|[the, eu, siding,...|\n",
      "|     0|   #   porn,   # ...|[porn, android, i...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|target|                text|               words|\n",
      "+------+--------------------+--------------------+\n",
      "|     0|Some women are ju...|[some, women, are...|\n",
      "|     0|Free Tay K   ?   ...|[free, tay, k, th...|\n",
      "|     1|   *   Insert edg...|[insert, edgy, co...|\n",
      "|     0|   @   lizforus L...|[lizforus, legal,...|\n",
      "|     1|   &   amp   ;   ...|[amp, these, bitc...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "raw_words_train = regex_tokenizer.transform(df_train)\n",
    "raw_words_test = regex_tokenizer.transform(df_test)\n",
    "raw_words_train.show(5)\n",
    "raw_words_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **StopWords:** <br>\n",
    "Stop words are commonly used words in a language that typically do not carry much meaning or contribute significantly to the overall understanding of a text. Examples of stop words in English include \"the\", \"is\", \"and\", \"a\", and \"an\". These words are often filtered out or removed from text data during natural language processing tasks, such as text classification or sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+\n",
      "|target|                text|               words|            filtered|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|     0|I, a Catholic and...|[i, a, catholic, ...|[catholic, jesuit...|\n",
      "|     1|ayo i even kill h...|[ayo, i, even, ki...|[ayo, even, kill,...|\n",
      "|     0|Trans rights are ...|[trans, rights, a...|[trans, rights, h...|\n",
      "|     0|the eu siding wit...|[the, eu, siding,...|[eu, siding, coun...|\n",
      "|     0|   #   porn,   # ...|[porn, android, i...|[porn, android, i...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|target|                text|               words|            filtered|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "|     0|Some women are ju...|[some, women, are...|[women, talented,...|\n",
      "|     0|Free Tay K   ?   ...|[free, tay, k, th...|[free, tay, k, ni...|\n",
      "|     1|   *   Insert edg...|[insert, edgy, co...|[insert, edgy, co...|\n",
      "|     0|   @   lizforus L...|[lizforus, legal,...|[lizforus, legal,...|\n",
      "|     1|   &   amp   ;   ...|[amp, these, bitc...|[amp, bitches, bo...|\n",
      "+------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "words_df_train = remover.transform(raw_words_train)\n",
    "words_df_test = remover.transform(raw_words_test)\n",
    "words_df_train.show(5)\n",
    "words_df_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **CountVectorizer:** <br>\n",
    "The CountVectorizer is a feature transformer that converts a collection of text documents into a matrix of token counts. It takes an input column of tokens and outputs a sparse vector representation of the token counts. In this case, the input column is \"tokens\" which contains the array of tokens generated by the Tokenizer. The CountVectorizer learns a vocabulary of distinct tokens from the training data and represents each document as a vector of token counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|target|                text|               words|            filtered|            features|label|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|     0|I, a Catholic and...|[i, a, catholic, ...|[catholic, jesuit...|(62068,[1,37,44,2...|    0|\n",
      "|     1|ayo i even kill h...|[ayo, i, even, ki...|[ayo, even, kill,...|(62068,[15,31,33,...|    1|\n",
      "|     0|Trans rights are ...|[trans, rights, a...|[trans, rights, h...|(62068,[27,49,60]...|    0|\n",
      "|     0|the eu siding wit...|[the, eu, siding,...|[eu, siding, coun...|(62068,[22,41,149...|    0|\n",
      "|     0|   #   porn,   # ...|[porn, android, i...|[porn, android, i...|(62068,[7,63,90,9...|    0|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 88:======>                                                   (1 + 8) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|target|                text|               words|            filtered|            features|label|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "|     0|Some women are ju...|[some, women, are...|[women, talented,...|(21455,[6,23,33,3...|    0|\n",
      "|     0|Free Tay K   ?   ...|[free, tay, k, th...|[free, tay, k, ni...|(21455,[20,36,204...|    0|\n",
      "|     1|   *   Insert edg...|[insert, edgy, co...|[insert, edgy, co...|(21455,[549,579,6...|    1|\n",
      "|     0|   @   lizforus L...|[lizforus, legal,...|[lizforus, legal,...|(21455,[232,819,9...|    0|\n",
      "|     1|   &   amp   ;   ...|[amp, these, bitc...|[amp, bitches, bo...|(21455,[4,5,36,71...|    1|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
    "\n",
    "# train\n",
    "model_train = cv.fit(words_df_train)\n",
    "countVectorizer_train = model_train.transform(words_df_train)\n",
    "countVectorizer_train = countVectorizer_train.withColumn(\"label\",col('target'))\n",
    "countVectorizer_train.show(5)\n",
    "\n",
    "# test\n",
    "model_test = cv.fit(words_df_test)\n",
    "countVectorizer_test = model_test.transform(words_df_test)\n",
    "countVectorizer_test= countVectorizer_test.withColumn(\"label\",col('target'))\n",
    "countVectorizer_test.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "As evaluation metrics ROC and Accuracy will be used. <br>\n",
    "\n",
    "* **ROC curve** is a graphical representation that shows the performance of a binary classification model as the decision threshold is varied. On the x-axis, the false positive rate (FPR) is plotted, which is the proportion of negative instances incorrectly classified as positive. On the y-axis, the true positive rate (TPR) is plotted, which is the proportion of positive instances correctly classified as positive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate train and validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, validate) = countVectorizer_train.randomSplit([0.8, 0.2],seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = countVectorizer_train\n",
    "testData = countVectorizer_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"label\", featuresCol=\"features\")\n",
    "nbModel = nb.fit(train)\n",
    "nb_predictions = nbModel.transform(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/19 14:24:19 WARN DAGScheduler: Broadcasting large task binary with size 1781.0 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC 0.5489994745013782\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator()\n",
    "print('Test Area Under ROC', evaluator.evaluate(nb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/19 14:24:26 WARN DAGScheduler: Broadcasting large task binary with size 1793.6 KiB\n",
      "23/07/19 14:24:27 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveBayes is = 0.779466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
    "print(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/19 14:24:47 WARN DAGScheduler: Broadcasting large task binary with size 1453.8 KiB\n",
      "23/07/19 14:25:10 WARN DAGScheduler: Broadcasting large task binary with size 1836.8 KiB\n",
      "23/07/19 14:25:11 WARN MemoryStore: Not enough space to cache rdd_399_0 in memory! (computed 149.3 MiB so far)\n",
      "23/07/19 14:25:11 WARN BlockManager: Persisting block rdd_399_0 to disk instead.\n",
      "23/07/19 14:26:19 WARN MemoryStore: Not enough space to cache rdd_399_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:26:51 WARN DAGScheduler: Broadcasting large task binary with size 1837.5 KiB\n",
      "23/07/19 14:26:51 WARN MemoryStore: Not enough space to cache rdd_399_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:27:23 WARN DAGScheduler: Broadcasting large task binary with size 1838.0 KiB\n",
      "23/07/19 14:27:24 WARN MemoryStore: Not enough space to cache rdd_399_0 in memory! (computed 339.9 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-----+-----------------+--------------------+----------+\n",
      "|target|                text|               words|            filtered|            features|label|    rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+-----------------+--------------------+----------+\n",
      "|     0|   !      !      ...|[rt, urkindofbran...|[rt, urkindofbran...|(62068,[3,4,13,25...|    0|[62818.0,28858.0]|[0.68521750512675...|       0.0|\n",
      "|     0|   !    thank u  ...|[thank, u, im, tr...|[thank, u, im, tr...|(62068,[9,18,29,3...|    0|[62818.0,28858.0]|[0.68521750512675...|       0.0|\n",
      "|     0|   !    thank u  ...|[thank, u, im, tr...|[thank, u, im, tr...|(62068,[9,18,29,3...|    0|[62818.0,28858.0]|[0.68521750512675...|       0.0|\n",
      "|     0|   #      #   Who...|[who, cares, prot...|[cares, protect, ...|(62068,[110,499,5...|    0|[62818.0,28858.0]|[0.68521750512675...|       0.0|\n",
      "|     0|   #   10ThingsTh...|[10thingsthatgets...|[10thingsthatgets...|(62068,[42,88,150...|    0|[62818.0,28858.0]|[0.68521750512675...|       0.0|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+-----------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'target', maxDepth = 3)\n",
    "dtModel = dt.fit(train)\n",
    "dtPreds = dtModel.transform(validate)\n",
    "dtPreds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Trees is = 0.70197\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "dt_accuracy = evaluator.evaluate(dtPreds)\n",
    "print(\"Accuracy of Decision Trees is = %g\"% (dt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBT Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/19 14:34:24 WARN DAGScheduler: Broadcasting large task binary with size 1453.5 KiB\n",
      "23/07/19 14:34:52 WARN DAGScheduler: Broadcasting large task binary with size 1841.6 KiB\n",
      "23/07/19 14:34:53 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 149.3 MiB so far)\n",
      "23/07/19 14:34:53 WARN BlockManager: Persisting block rdd_606_0 to disk instead.\n",
      "23/07/19 14:36:01 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:36:01 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 14:36:58 WARN DAGScheduler: Broadcasting large task binary with size 1842.4 KiB\n",
      "23/07/19 14:36:59 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:37:33 WARN DAGScheduler: Broadcasting large task binary with size 1842.9 KiB\n",
      "23/07/19 14:37:34 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:38:08 WARN DAGScheduler: Broadcasting large task binary with size 1843.8 KiB\n",
      "23/07/19 14:38:08 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:38:42 WARN DAGScheduler: Broadcasting large task binary with size 1845.1 KiB\n",
      "23/07/19 14:38:43 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:39:17 WARN DAGScheduler: Broadcasting large task binary with size 1850.5 KiB\n",
      "23/07/19 14:39:18 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:39:18 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 14:39:18 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 14:39:30 WARN MemoryStore: Not enough space to cache rdd_626_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:39:30 WARN BlockManager: Persisting block rdd_626_0 to disk instead.\n",
      "23/07/19 14:39:41 WARN MemoryStore: Not enough space to cache rdd_626_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:40:37 WARN DAGScheduler: Broadcasting large task binary with size 1851.0 KiB\n",
      "23/07/19 14:40:38 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:41:12 WARN DAGScheduler: Broadcasting large task binary with size 1851.5 KiB\n",
      "23/07/19 14:41:13 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:41:47 WARN DAGScheduler: Broadcasting large task binary with size 1852.4 KiB\n",
      "23/07/19 14:41:47 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:42:22 WARN DAGScheduler: Broadcasting large task binary with size 1854.1 KiB\n",
      "23/07/19 14:42:22 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:42:56 WARN DAGScheduler: Broadcasting large task binary with size 1856.5 KiB\n",
      "23/07/19 14:42:57 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:42:57 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 14:42:57 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 14:42:57 WARN MemoryStore: Not enough space to cache rdd_626_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:42:57 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_648_0 in memory.\n",
      "23/07/19 14:42:57 WARN MemoryStore: Not enough space to cache rdd_648_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 14:42:57 WARN BlockManager: Persisting block rdd_648_0 to disk instead.\n",
      "23/07/19 14:43:20 WARN MemoryStore: Not enough space to cache rdd_648_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:44:17 WARN DAGScheduler: Broadcasting large task binary with size 1857.0 KiB\n",
      "23/07/19 14:44:17 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:44:52 WARN DAGScheduler: Broadcasting large task binary with size 1857.6 KiB\n",
      "23/07/19 14:44:52 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:45:27 WARN DAGScheduler: Broadcasting large task binary with size 1858.5 KiB\n",
      "23/07/19 14:45:28 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:46:03 WARN DAGScheduler: Broadcasting large task binary with size 1860.1 KiB\n",
      "23/07/19 14:46:03 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:46:38 WARN DAGScheduler: Broadcasting large task binary with size 1862.5 KiB\n",
      "23/07/19 14:46:38 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:46:38 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 14:46:39 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 14:46:39 WARN MemoryStore: Not enough space to cache rdd_648_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:46:39 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_670_0 in memory.\n",
      "23/07/19 14:46:39 WARN MemoryStore: Not enough space to cache rdd_670_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 14:46:39 WARN BlockManager: Persisting block rdd_670_0 to disk instead.\n",
      "23/07/19 14:47:01 WARN MemoryStore: Not enough space to cache rdd_670_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:47:58 WARN DAGScheduler: Broadcasting large task binary with size 1863.0 KiB\n",
      "23/07/19 14:47:59 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:48:33 WARN DAGScheduler: Broadcasting large task binary with size 1863.5 KiB\n",
      "23/07/19 14:48:33 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:49:08 WARN DAGScheduler: Broadcasting large task binary with size 1864.7 KiB\n",
      "23/07/19 14:49:08 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:49:43 WARN DAGScheduler: Broadcasting large task binary with size 1866.4 KiB\n",
      "23/07/19 14:49:43 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:50:17 WARN DAGScheduler: Broadcasting large task binary with size 1867.7 KiB\n",
      "23/07/19 14:50:18 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:50:18 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 14:50:18 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 14:50:18 WARN MemoryStore: Not enough space to cache rdd_670_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:50:18 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_692_0 in memory.\n",
      "23/07/19 14:50:18 WARN MemoryStore: Not enough space to cache rdd_692_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 14:50:18 WARN BlockManager: Persisting block rdd_692_0 to disk instead.\n",
      "23/07/19 14:50:41 WARN MemoryStore: Not enough space to cache rdd_692_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:51:37 WARN DAGScheduler: Broadcasting large task binary with size 1868.1 KiB\n",
      "23/07/19 14:51:38 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:52:12 WARN DAGScheduler: Broadcasting large task binary with size 1868.7 KiB\n",
      "23/07/19 14:52:12 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:52:46 WARN DAGScheduler: Broadcasting large task binary with size 1869.6 KiB\n",
      "23/07/19 14:52:47 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:53:21 WARN DAGScheduler: Broadcasting large task binary with size 1871.3 KiB\n",
      "23/07/19 14:53:22 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:53:56 WARN DAGScheduler: Broadcasting large task binary with size 1873.0 KiB\n",
      "23/07/19 14:53:56 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:53:56 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 14:53:56 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 14:53:57 WARN MemoryStore: Not enough space to cache rdd_692_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:53:57 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_714_0 in memory.\n",
      "23/07/19 14:53:57 WARN MemoryStore: Not enough space to cache rdd_714_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 14:53:57 WARN BlockManager: Persisting block rdd_714_0 to disk instead.\n",
      "23/07/19 14:54:20 WARN MemoryStore: Not enough space to cache rdd_714_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:55:16 WARN DAGScheduler: Broadcasting large task binary with size 1873.5 KiB\n",
      "23/07/19 14:55:16 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:55:50 WARN DAGScheduler: Broadcasting large task binary with size 1874.0 KiB\n",
      "23/07/19 14:55:51 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:56:25 WARN DAGScheduler: Broadcasting large task binary with size 1875.2 KiB\n",
      "23/07/19 14:56:25 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:56:59 WARN DAGScheduler: Broadcasting large task binary with size 1877.2 KiB\n",
      "23/07/19 14:57:00 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:57:34 WARN DAGScheduler: Broadcasting large task binary with size 1878.5 KiB\n",
      "23/07/19 14:57:34 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:57:34 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 14:57:34 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 14:57:34 WARN MemoryStore: Not enough space to cache rdd_714_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:57:34 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_736_0 in memory.\n",
      "23/07/19 14:57:34 WARN MemoryStore: Not enough space to cache rdd_736_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 14:57:34 WARN BlockManager: Persisting block rdd_736_0 to disk instead.\n",
      "23/07/19 14:57:57 WARN MemoryStore: Not enough space to cache rdd_736_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 14:58:53 WARN DAGScheduler: Broadcasting large task binary with size 1879.0 KiB\n",
      "23/07/19 14:58:54 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 14:59:27 WARN DAGScheduler: Broadcasting large task binary with size 1879.6 KiB\n",
      "23/07/19 14:59:28 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:00:01 WARN DAGScheduler: Broadcasting large task binary with size 1880.7 KiB\n",
      "23/07/19 15:00:02 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:00:36 WARN DAGScheduler: Broadcasting large task binary with size 1882.4 KiB\n",
      "23/07/19 15:00:36 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:01:10 WARN DAGScheduler: Broadcasting large task binary with size 1884.2 KiB\n",
      "23/07/19 15:01:11 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:01:11 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 15:01:11 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 15:01:11 WARN MemoryStore: Not enough space to cache rdd_736_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 15:01:11 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_758_0 in memory.\n",
      "23/07/19 15:01:11 WARN MemoryStore: Not enough space to cache rdd_758_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 15:01:11 WARN BlockManager: Persisting block rdd_758_0 to disk instead.\n",
      "23/07/19 15:01:33 WARN MemoryStore: Not enough space to cache rdd_758_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 15:02:29 WARN DAGScheduler: Broadcasting large task binary with size 1884.7 KiB\n",
      "23/07/19 15:02:30 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:03:03 WARN DAGScheduler: Broadcasting large task binary with size 1885.2 KiB\n",
      "23/07/19 15:03:04 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:03:38 WARN DAGScheduler: Broadcasting large task binary with size 1886.4 KiB\n",
      "23/07/19 15:03:38 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:04:12 WARN DAGScheduler: Broadcasting large task binary with size 1888.4 KiB\n",
      "23/07/19 15:04:13 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:04:46 WARN DAGScheduler: Broadcasting large task binary with size 1890.3 KiB\n",
      "23/07/19 15:04:47 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:04:47 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 15:04:47 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 15:04:47 WARN MemoryStore: Not enough space to cache rdd_758_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 15:04:47 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_780_0 in memory.\n",
      "23/07/19 15:04:47 WARN MemoryStore: Not enough space to cache rdd_780_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 15:04:47 WARN BlockManager: Persisting block rdd_780_0 to disk instead.\n",
      "23/07/19 15:05:10 WARN MemoryStore: Not enough space to cache rdd_780_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 15:06:06 WARN DAGScheduler: Broadcasting large task binary with size 1890.8 KiB\n",
      "23/07/19 15:06:06 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:06:40 WARN DAGScheduler: Broadcasting large task binary with size 1891.4 KiB\n",
      "23/07/19 15:06:40 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:07:14 WARN DAGScheduler: Broadcasting large task binary with size 1892.3 KiB\n",
      "23/07/19 15:07:14 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:07:48 WARN DAGScheduler: Broadcasting large task binary with size 1893.9 KiB\n",
      "23/07/19 15:07:48 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:08:22 WARN DAGScheduler: Broadcasting large task binary with size 1895.7 KiB\n",
      "23/07/19 15:08:23 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:08:23 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 26.8 MiB so far)\n",
      "23/07/19 15:08:23 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 4.0 MiB so far)\n",
      "23/07/19 15:08:23 WARN MemoryStore: Not enough space to cache rdd_780_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 15:08:23 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_802_0 in memory.\n",
      "23/07/19 15:08:23 WARN MemoryStore: Not enough space to cache rdd_802_0 in memory! (computed 384.0 B so far)\n",
      "23/07/19 15:08:23 WARN BlockManager: Persisting block rdd_802_0 to disk instead.\n",
      "23/07/19 15:08:45 WARN MemoryStore: Not enough space to cache rdd_802_0 in memory! (computed 2.4 MiB so far)\n",
      "23/07/19 15:09:41 WARN DAGScheduler: Broadcasting large task binary with size 1896.2 KiB\n",
      "23/07/19 15:09:42 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:10:15 WARN DAGScheduler: Broadcasting large task binary with size 1896.7 KiB\n",
      "23/07/19 15:10:16 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:10:50 WARN DAGScheduler: Broadcasting large task binary with size 1897.9 KiB\n",
      "23/07/19 15:10:50 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "23/07/19 15:11:24 WARN DAGScheduler: Broadcasting large task binary with size 1899.8 KiB\n",
      "23/07/19 15:11:25 WARN MemoryStore: Not enough space to cache rdd_606_0 in memory! (computed 339.9 MiB so far)\n",
      "[Stage 458:=======>                                                 (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|target|                text|               words|            filtered|            features|label|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|     0|   !      !      ...|[rt, urkindofbran...|[rt, urkindofbran...|(62068,[3,4,13,25...|    0|[0.38832960984962...|[0.68495965305164...|       0.0|\n",
      "|     0|   !    thank u  ...|[thank, u, im, tr...|[thank, u, im, tr...|(62068,[9,18,29,3...|    0|[0.46945988608090...|[0.71888140479252...|       0.0|\n",
      "|     0|   !    thank u  ...|[thank, u, im, tr...|[thank, u, im, tr...|(62068,[9,18,29,3...|    0|[0.46945988608090...|[0.71888140479252...|       0.0|\n",
      "|     0|   #      #   Who...|[who, cares, prot...|[cares, protect, ...|(62068,[110,499,5...|    0|[0.46945988608090...|[0.71888140479252...|       0.0|\n",
      "|     0|   #   10ThingsTh...|[10thingsthatgets...|[10thingsthatgets...|(62068,[42,88,150...|    0|[0.46945988608090...|[0.71888140479252...|       0.0|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "gbt = GBTClassifier(maxIter=10)\n",
    "gbtModel = gbt.fit(train)\n",
    "gbtPreds = gbtModel.transform(validate)\n",
    "gbtPreds.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Area Under ROC: 0.7921680466831243\n"
     ]
    }
   ],
   "source": [
    "gbtEval = BinaryClassificationEvaluator()\n",
    "gbtROC = gbtEval.evaluate(gbtPreds, {gbtEval.metricName: \"areaUnderROC\"})\n",
    "print(\"Test Area Under ROC: \" + str(gbtROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 487:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of GBT is = 0.759571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "gb_accuracy = evaluator.evaluate(gbtPreds)\n",
    "print(\"Accuracy of GBT is = %g\"% (gb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBTClassifier is used to make predictions because it has the best evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 649:>                                                        (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(maxIter=10)\n",
    "gbtModel = gbt.fit(trainData)\n",
    "gbtPreds = gbtModel.transform(testData)\n",
    "predictions = gbtPreds.select('id','prediction')\n",
    "predictions.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
